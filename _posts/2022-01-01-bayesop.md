---
title: "Bayes 优化简介"
categories: 
- Machine Learning
updated: 2022-02-05
comments: true
mathjax: true
---

首先强烈推荐 

- Frazier, P. I. (2018). [A tutorial on Bayesian optimization](https://arxiv.org/abs/1807.02811). *arXiv Preprint arXiv:1807.02811*.

写得非常清楚. 本文只简单介绍最基本的内容.

考虑优化问题 

$$
\max_{x\in A} f(x),
$$

Bayesian optimization is designed for black-box derivative-free global optimization. 黑箱意思是不知道函数 $f$ 的形式和性质 (凸性等), 只能通过输入 $x$ 得到输出 $f(x)$, 另外也不知道导数信息, 目标是求解全局最优.

<!-- more -->

Bayes 优化由两部分组成: 目标函数上的 Bayes 模型, 以及用来决定下一步输入哪个值的 acquisition function. 场景是每次输入 $x$ 得到输出 $f(x)$ 有一定成本 (比如时间成本), 希望试最少的次数得到最大值.

![](https://shiina18.github.io/assets/posts/images/20211204105530317_13090.png)

## Gaussian Process (GP) Regression

GP regression is a Bayesian statistical approach for modeling functions. 现在有 $k$ 个点上的函数值 $f(x_{1:k}) := (f(x_1), \dots, f(x_k))$, 假设它是服从某个先验分布的随机向量的一个具体观测值. GP 把这个先验分布取为多元正态分布

$$
f(x_{1:k}) \sim \operatorname{Normal} (\mu_0(x_{1:k}), \Sigma_0(x_{1:k}, x_{1:k})),
$$

其中 $\mu_0$ 和 $\Sigma_0$ 自定义 (这里会引入新的超参数, 略). 对于新的点 $x$, 考虑后验分布 (条件分布) $f(x) \mid f(x_{1:k})$, 它也是多元正态分布.

## Acquisition functions

The most commonly used acquisition function is expected improvement. (此外还有 knowledge gradient, entropy search and predictive entropy search 等.) 要决定下一个点 $x$ 试哪里收益高, EI 根据历史观测, 取期望增益 (相比历史观测最大值) 最高的点, 即

$$
\operatorname{EI}_k(x) = \mathbb E_k \max(0, f(x) - \max_{j\le k} f(x_j)),
$$

其中 $\mathbb E_k$ 对应的分布为观测 $k$ 个点的后验分布. 然后下一个点 $x_{k+1}$ 取为使这个期望最大的点

$$
x_{k+1} = \operatorname{argmax} \operatorname{EI}_k(x).
$$

![](https://shiina18.github.io/assets/posts/images/147071516220142.png)

总得来说贝叶斯优化把原先的寻找超参数问题转换为在 surrogate model (GP) 上调超参, 求解 acquisition function 最大值的问题.

## Further reading

- [Bayesian Optimization: does it work?](https://www.reddit.com/r/MachineLearning/comments/fsupfu/d_bayesian_optimization_does_it_work/)
- [Exploring Bayesian Optimization](https://distill.pub/2020/bayesian-optimization/). 可以看文章底下收集的一些包.
- [为什么基于贝叶斯优化的自动调参没有大范围使用?](https://www.zhihu.com/question/33711002) 
    - 不过之前看到 AlphaGo (Mastering the game of Go without human knowledge) 在某个地方用到了贝叶斯优化 .
- Ouyang, Y. (2022, Feb 4). [Using Bayesian optimization for balancing metrics in recommendation systems](https://engineering.linkedin.com/blog/2022/using-bayesian-optimization-for-balancing-metrics-in-recommendat). *LinkedIn Engineering*.